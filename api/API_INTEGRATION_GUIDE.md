# ğŸ¥Š CUENet Fight Detection - HÆ°á»›ng Dáº«n TÃ­ch Há»£p API

## ğŸ“‹ Tá»•ng Quan

API nÃ y cho phÃ©p báº¡n tÃ­ch há»£p model **CUENet** vÃ o á»©ng dá»¥ng Streamlit Ä‘á»ƒ phÃ¡t hiá»‡n Ä‘Ã¡nh nhau trong video.

### Model Performance
| Metric | GiÃ¡ trá»‹ |
|--------|---------|
| **Accuracy** | 90.75% |
| **F1-Score** | 90.75% |
| **ROC-AUC** | 0.969 |

---

## ğŸ“¦ Files Cáº§n Thiáº¿t

### 1. Tá»« Google Drive (báº¡n sáº½ nháº­n link):
```
cuenet_rwf2000_epoch51.pyth  (~2.5GB) - Model checkpoint
vit_l14_336.pth              (~1.7GB) - CLIP backbone weights
```

### 2. Tá»« Repository:
```
api/
  â””â”€â”€ fight_detection_api.py   # API server code
UniFormerV2/                   # Model code (cáº£ folder)
```

---

## ğŸš€ CÃ i Äáº·t

### BÆ°á»›c 1: Clone/Copy Files

```bash
# Copy toÃ n bá»™ folder UniFormerV2 vÃ  api/ vÃ o project cá»§a báº¡n
your_project/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ fight_detection_api.py
â”œâ”€â”€ UniFormerV2/
â”‚   â”œâ”€â”€ exp/
â”‚   â”‚   â””â”€â”€ RWF_exp/
â”‚   â”‚       â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ model_chkpts/
â”‚   â”‚   â””â”€â”€ vit_l14_336.pth    # â¬…ï¸ Download tá»« Drive
â”‚   â””â”€â”€ slowfast/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cuenet_rwf2000_epoch51.pyth  # â¬…ï¸ Download tá»« Drive
â””â”€â”€ your_streamlit_app.py
```

### BÆ°á»›c 2: CÃ i Dependencies

```bash
pip install fastapi uvicorn python-multipart
pip install torch torchvision  # Náº¿u chÆ°a cÃ³
pip install opencv-python-headless numpy
pip install fvcore iopath yacs termcolor
pip install pytorchvideo timm einops

# Install UniFormerV2
cd UniFormerV2
pip install -e .
```

### BÆ°á»›c 3: Download Model Files tá»« Google Drive

1. Download `cuenet_rwf2000_epoch51.pyth` â†’ Ä‘áº·t vÃ o `models/`
2. Download `vit_l14_336.pth` â†’ Ä‘áº·t vÃ o `UniFormerV2/model_chkpts/`

---

## ğŸƒ Cháº¡y API Server

### Option 1: Command Line

```bash
cd your_project/api
python fight_detection_api.py --host 0.0.0.0 --port 8000
```

### Option 2: Vá»›i Uvicorn

```bash
cd your_project/api
uvicorn fight_detection_api:app --host 0.0.0.0 --port 8000 --reload
```

### Kiá»ƒm tra API Ä‘ang cháº¡y:
- Má»Ÿ browser: http://localhost:8000
- API docs: http://localhost:8000/docs

---

## ğŸ“¡ API Endpoints

### 1. Health Check

```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cuda",
  "message": "Model loaded and ready"
}
```

### 2. Predict Video

```http
POST /predict
Content-Type: multipart/form-data
```

**Request:** Upload video file (mp4, avi, mov, mkv, webm)

**Response:**
```json
{
  "success": true,
  "prediction": "Fight",
  "confidence": 95.32,
  "probabilities": {
    "NonFight": 4.68,
    "Fight": 95.32
  },
  "message": "Video classified as Fight with 95.32% confidence",
  "processing_time": 2.45
}
```

---

## ğŸ¨ TÃ­ch Há»£p VÃ o Streamlit

### CÃ¡ch 1: Gá»i API tá»« Streamlit

```python
import streamlit as st
import requests

st.title("ğŸ¥Š Fight Detection Demo")

# Upload video
uploaded_file = st.file_uploader("Upload video", type=['mp4', 'avi', 'mov'])

if uploaded_file is not None:
    # Hiá»ƒn thá»‹ video
    st.video(uploaded_file)
    
    if st.button("ğŸ” Detect Fight"):
        with st.spinner("Analyzing video..."):
            # Gá»i API
            files = {"file": (uploaded_file.name, uploaded_file.getvalue())}
            response = requests.post(
                "http://localhost:8000/predict",
                files=files
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # Hiá»ƒn thá»‹ káº¿t quáº£
                col1, col2 = st.columns(2)
                
                with col1:
                    if result["prediction"] == "Fight":
                        st.error(f"ğŸš¨ FIGHT DETECTED!")
                    else:
                        st.success(f"âœ… No Fight")
                
                with col2:
                    st.metric("Confidence", f"{result['confidence']:.2f}%")
                
                # Progress bars
                st.write("**Probabilities:**")
                st.progress(result["probabilities"]["Fight"] / 100)
                st.caption(f"Fight: {result['probabilities']['Fight']:.2f}%")
                st.progress(result["probabilities"]["NonFight"] / 100)
                st.caption(f"NonFight: {result['probabilities']['NonFight']:.2f}%")
                
            else:
                st.error(f"Error: {response.text}")
```

### CÃ¡ch 2: Import trá»±c tiáº¿p Model (khÃ´ng cáº§n API server)

```python
import streamlit as st
import sys
from pathlib import Path

# Add paths
sys.path.insert(0, str(Path("UniFormerV2/slowfast")))
sys.path.insert(0, str(Path("UniFormerV2")))

# Import model class
from api.fight_detection_api import FightDetectionModel

# Load model (cache Ä‘á»ƒ khÃ´ng load láº¡i má»—i láº§n)
@st.cache_resource
def load_model():
    model = FightDetectionModel()
    model.load(
        checkpoint_path="models/cuenet_rwf2000_epoch51.pyth",
        config_path="UniFormerV2/exp/RWF_exp/config.yaml"
    )
    return model

model = load_model()

st.title("ğŸ¥Š Fight Detection Demo")

uploaded_file = st.file_uploader("Upload video", type=['mp4', 'avi', 'mov'])

if uploaded_file is not None:
    # Save temp file
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:
        tmp.write(uploaded_file.getvalue())
        tmp_path = tmp.name
    
    st.video(uploaded_file)
    
    if st.button("ğŸ” Detect Fight"):
        with st.spinner("Analyzing..."):
            result = model.predict(tmp_path)
            
            if result["prediction"] == "Fight":
                st.error(f"ğŸš¨ FIGHT DETECTED! ({result['confidence']:.2f}%)")
            else:
                st.success(f"âœ… No Fight ({result['confidence']:.2f}%)")
```

---

## âš ï¸ LÆ°u Ã Quan Trá»ng

### 1. GPU vs CPU
- **CÃ³ GPU**: ~2-3 giÃ¢y/video
- **Chá»‰ CPU**: ~30-60 giÃ¢y/video (ráº¥t cháº­m!)

Kiá»ƒm tra GPU:
```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}")
```

### 2. Memory Requirements
- **GPU Memory**: ~8GB VRAM
- **RAM**: ~16GB recommended

### 3. Video Format
- Há»— trá»£: `.mp4`, `.avi`, `.mov`, `.mkv`, `.webm`
- Khuyáº¿n nghá»‹: `.mp4` (H.264 codec)

### 4. Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

**Lá»—i: "CLIP weights not found"**
```bash
# Äáº£m báº£o file vit_l14_336.pth náº±m Ä‘Ãºng vá»‹ trÃ­
UniFormerV2/model_chkpts/vit_l14_336.pth
```

**Lá»—i: "Model not loaded"**
```bash
# Kiá»ƒm tra checkpoint file
ls -lh models/cuenet_rwf2000_epoch51.pyth
```

**Lá»—i: "CUDA out of memory"**
```python
# Giáº£m batch size hoáº·c dÃ¹ng CPU
import torch
torch.cuda.empty_cache()
```

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c HoÃ n Chá»‰nh

```
your_project/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ fight_detection_api.py     # API server
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cuenet_rwf2000_epoch51.pyth  # Model checkpoint (tá»« Drive)
â”œâ”€â”€ UniFormerV2/
â”‚   â”œâ”€â”€ exp/
â”‚   â”‚   â””â”€â”€ RWF_exp/
â”‚   â”‚       â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ model_chkpts/
â”‚   â”‚   â””â”€â”€ vit_l14_336.pth        # CLIP weights (tá»« Drive)
â”‚   â”œâ”€â”€ slowfast/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ setup.py
â”œâ”€â”€ your_streamlit_app.py
â””â”€â”€ requirements.txt
```

---

## ğŸ“ Há»— Trá»£

Náº¿u gáº·p váº¥n Ä‘á»:
1. Kiá»ƒm tra logs cá»§a API server
2. Äáº£m báº£o táº¥t cáº£ dependencies Ä‘Ã£ cÃ i Ä‘Ãºng
3. Kiá»ƒm tra paths trong `fight_detection_api.py`

**ChÃºc báº¡n demo thÃ nh cÃ´ng! ğŸ‰**
