# CUE-Net: Violence Detection in Surveillance Videos

Äá»“ Ã¡n mÃ´n há»c CS231 - Nháº­n dáº¡ng thá»‹ giÃ¡c nÃ¢ng cao

## ğŸ“‹ Giá»›i thiá»‡u

ÄÃ¢y lÃ  repository chá»©a mÃ£ nguá»“n triá»ƒn khai mÃ´ hÃ¬nh **CUE-Net** (CLIP-based UniFormerV2 Enhanced Network) cho bÃ i toÃ¡n phÃ¡t hiá»‡n báº¡o lá»±c tá»« video giÃ¡m sÃ¡t, sá»­ dá»¥ng bá»™ dá»¯ liá»‡u **RWF-2000**.

## ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh

CUE-Net Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn **UniFormerV2** vá»›i backbone **CLIP ViT-L/14-336**, káº¿t há»£p:
- **Local UniBlocks**: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng khÃ´ng gian-thá»i gian cá»¥c bá»™
- **Global UniBlocks (MEAA)**: Multi-Head Efficient Additive Attention cho ngá»¯ cáº£nh toÃ n cá»¥c
- **CLIP Pre-training**: Táº­n dá»¥ng tri thá»©c tá»« mÃ´ hÃ¬nh vision-language quy mÃ´ lá»›n

### ThÃ´ng sá»‘ mÃ´ hÃ¬nh
| ThÃ´ng sá»‘ | GiÃ¡ trá»‹ |
|----------|---------|
| Backbone | CLIP ViT-L/14-336 |
| Input size | 336 Ã— 336 Ã— 64 frames |
| Num classes | 2 (Fight/NonFight) |
| Total parameters | ~354M |
| Global UniBlocks | 4 layers |
| Hidden dim | 1024 |
| Attention heads | 16 |

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
cs231_cuenet/
â”œâ”€â”€ UniFormerV2/                    # Core model code
â”‚   â”œâ”€â”€ slowfast/
â”‚   â”‚   â”œâ”€â”€ config/                 # Configuration files
â”‚   â”‚   â”œâ”€â”€ models/                 # Model architecture
â”‚   â”‚   â”‚   â”œâ”€â”€ uniformerv2.py      # Wrapper class
â”‚   â”‚   â”‚   â”œâ”€â”€ uniformerv2_model.py # Core model implementation
â”‚   â”‚   â”‚   â””â”€â”€ build.py            # Model builder
â”‚   â”‚   â”œâ”€â”€ datasets/               # Data loading
â”‚   â”‚   â””â”€â”€ utils/                  # Utilities
â”‚   â”œâ”€â”€ exp/
â”‚   â”‚   â””â”€â”€ RWF_exp/
â”‚   â”‚       â””â”€â”€ config.yaml         # Training configuration
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ train_net.py            # Training script
â”‚       â””â”€â”€ test_net.py             # Testing script
â”‚
â”œâ”€â”€ data_paths/                     # Dataset split files
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ val.csv
â”‚   â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ models/                         # Trained checkpoints
â”‚   â””â”€â”€ cuenet_rwf2000_epoch51.pyth
â”‚
â”œâ”€â”€ api/                            # Inference API
â”‚   â””â”€â”€ fight_detection_api.py
â”‚
â”œâ”€â”€ visualizations/                 # Output visualizations
â”‚
â”œâ”€â”€ inference_single_video.py       # Single video inference
â”œâ”€â”€ evaluate_validation.py          # Evaluation script
â”œâ”€â”€ visualize_meaningful_v2.py      # Feature visualization (Eigen-CAM)
â”œâ”€â”€ create_csv.py                   # Create dataset CSV files
â””â”€â”€ README.md
```

## âš™ï¸ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- PyTorch 2.0+ vá»›i CUDA support
- GPU vá»›i â‰¥4GB VRAM (inference) hoáº·c â‰¥48GB VRAM (training)

### CÃ¡c bÆ°á»›c cÃ i Ä‘áº·t

```bash
# 1. Clone repository
git clone https://github.com/manhdungcr7/cs231_cuenet.git
cd cs231_cuenet

# 2. CÃ i Ä‘áº·t dependencies
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install fvcore iopath simplejson psutil opencv-python tensorboard
pip install timm einops decord pytorchvideo

# 3. CÃ i Ä‘áº·t slowfast
cd UniFormerV2
pip install -e .
cd ..

# 4. Táº£i CLIP weights (ViT-L/14-336)
# File: vit_l14_336.pth â†’ Ä‘áº·t vÃ o UniFormerV2/model_chkpts/
```

## ğŸš€ Sá»­ dá»¥ng

### Inference trÃªn video Ä‘Æ¡n

```python
python inference_single_video.py --video path/to/video.avi
```

### ÄÃ¡nh giÃ¡ trÃªn táº­p validation

```python
python evaluate_validation.py
```

### Visualization (Eigen-CAM + Temporal Importance)

```python
python visualize_meaningful_v2.py --video path/to/video.avi
```

## ğŸ“Š Káº¿t quáº£

| Model | Dataset | Accuracy | F1-Score |
|-------|---------|----------|----------|
| CUE-Net | RWF-2000 | **89.50%** | **89.48%** |
| FlowGate Network | RWF-2000 | 85.25% | 85.20% |

## ğŸ”§ Training

Äá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»« Ä‘áº§u (yÃªu cáº§u GPU 48GB+):

```bash
cd UniFormerV2

# Training
python tools/train_net.py \
  --cfg exp/RWF_exp/config.yaml \
  DATA.PATH_TO_DATA_DIR /path/to/rwf2000 \
  NUM_GPUS 1 \
  TRAIN.BATCH_SIZE 2
```

### Cáº¥u hÃ¬nh huáº¥n luyá»‡n chÃ­nh
- **Optimizer**: AdamW (weight decay = 0.05)
- **Learning rate**: 4e-4 vá»›i Cosine scheduler
- **Epochs**: 51
- **Batch size**: 2-4 (tÃ¹y VRAM)
- **Dropout**: 0.5

## ğŸ“š TÃ i liá»‡u tham kháº£o

1. [UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video UniFormer](https://arxiv.org/abs/2211.09552)
2. [Learning to Recognize Actions on Objects in Egocentric Video with Attention Dictionaries](https://arxiv.org/abs/2102.06694)
3. [RWF-2000: An Open Large Scale Video Database for Violence Detection](https://arxiv.org/abs/1911.05913)

## ğŸ‘¨â€ğŸ’» TÃ¡c giáº£

- **Há» tÃªn**: [Äiá»n tÃªn sinh viÃªn]
- **MSSV**: [Äiá»n MSSV]
- **Email**: [Äiá»n email]

## ğŸ“„ License

MIT License
