# ğŸ¥Š CUENet Fight Detection

> **CUE-Net: Violence Detection Video Analytics with Spatial Cropping, Enhanced UniformerV2 and Modified Efficient Additive Attention**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“Š Model Performance

| Metric | Value |
|--------|-------|
| **Accuracy** | 90.75% |
| **Precision** | 90.83% |
| **Recall** | 90.75% |
| **F1-Score** | 90.75% |
| **ROC-AUC** | 0.969 |

Trained on **RWF-2000** dataset (Real World Fight).

---

## ğŸ—ï¸ Architecture

**CUE-Net** lÃ  kiáº¿n trÃºc 3 module:

1. **C (Cropping)**: YOLOv8 spatial cropping - táº­p trung vÃ o vÃ¹ng cÃ³ ngÆ°á»i
2. **U (UniFormerV2)**: Backbone káº¿t há»£p CNN + Self-Attention  
3. **E (Enhanced)**: MEAA (Modified Efficient Additive Attention) - giáº£m Ä‘á»™ phá»©c táº¡p tá»« O(LÂ²) â†’ O(L)

---

## ğŸ“ Project Structure

```
fight_detection/
â”œâ”€â”€ api/                          # ğŸ†• API cho web demo
â”‚   â”œâ”€â”€ fight_detection_api.py    # FastAPI server
â”‚   â”œâ”€â”€ API_INTEGRATION_GUIDE.md  # HÆ°á»›ng dáº«n tÃ­ch há»£p
â”‚   â””â”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ models/                       # Model checkpoints (download separately)
â”œâ”€â”€ UniFormerV2/                  # Model code
â”‚   â”œâ”€â”€ exp/RWF_exp/config.yaml   # Training config
â”‚   â”œâ”€â”€ model_chkpts/             # CLIP weights (download separately)
â”‚   â””â”€â”€ slowfast/                 # Core framework
â”œâ”€â”€ data_paths/                   # CSV files for dataset
â”œâ”€â”€ batch_inference.py            # Batch prediction
â”œâ”€â”€ inference_single_video.py     # Single video prediction
â”œâ”€â”€ evaluate_validation.py        # Validation evaluation
â”œâ”€â”€ run_cropping.py               # YOLOv8 spatial cropping
â””â”€â”€ create_csv.py                 # Create dataset CSV
```

---

## ğŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/manhdungcr7/fight_detection.git
cd fight_detection
```

### 2. Install Dependencies

```bash
pip install torch torchvision
pip install opencv-python-headless numpy tqdm
pip install fvcore iopath yacs termcolor
pip install pytorchvideo timm einops

# Install UniFormerV2
cd UniFormerV2
pip install -e .
```

### 3. Download Model Weights

Download tá»« Google Drive vÃ  Ä‘áº·t vÃ o Ä‘Ãºng folder:

| File | Size | Location |
|------|------|----------|
| `cuenet_rwf2000_epoch51.pyth` | ~2.5GB | `models/` |
| `vit_l14_336.pth` | ~1.7GB | `UniFormerV2/model_chkpts/` |

### 4. Run Inference

```bash
# Single video
python inference_single_video.py --video path/to/video.mp4

# Batch inference
python batch_inference.py --input_dir path/to/videos --output_dir results/
```

---

## ğŸŒ API for Web Demo

### Start API Server

```bash
cd api
pip install -r requirements.txt
python fight_detection_api.py --port 8000
```

### API Endpoints

```http
GET  /health              # Health check
POST /predict             # Upload video and get prediction
```

### Example Response

```json
{
  "success": true,
  "prediction": "Fight",
  "confidence": 95.32,
  "probabilities": {
    "NonFight": 4.68,
    "Fight": 95.32
  },
  "processing_time": 2.45
}
```

### Streamlit Integration

```python
import requests

files = {"file": open("video.mp4", "rb")}
response = requests.post("http://localhost:8000/predict", files=files)
result = response.json()

print(f"Prediction: {result['prediction']}")
print(f"Confidence: {result['confidence']:.2f}%")
```

See [API_INTEGRATION_GUIDE.md](api/API_INTEGRATION_GUIDE.md) for detailed instructions.

---

## ğŸ“¦ Dataset

**RWF-2000** (Real World Fight):
- **Train**: 1600 videos (800 Fight + 800 NonFight)
- **Validation**: 400 videos (200 Fight + 200 NonFight)

Dataset khÃ´ng Ä‘Æ°á»£c bao gá»“m trong repo. Táº£i tá»« [official source](https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection).

---

## ğŸ”§ Training (Optional)

### On Kaggle (Free GPU)

1. Upload datasets lÃªn Kaggle Datasets
2. Sá»­ dá»¥ng notebook `cuenet-evaluation.ipynb`
3. Enable GPU T4 vÃ  Run All

### Local/Cloud

```bash
cd UniFormerV2
python tools/run_net.py --cfg exp/RWF_exp/config.yaml
```

---

## ğŸ“š References

- **Paper**: [CUE-Net (CVPR 2024 Workshop)](https://openaccess.thecvf.com/content/CVPR2024W/ABAW/papers/Senadeera_CUE-Net_Violence_Detection_Video_Analytics_with_Spatial_Cropping_Enhanced_UniformerV2_CVPRW_2024_paper.pdf)
- **UniFormerV2**: [GitHub](https://github.com/OpenGVLab/UniFormerV2)
- **RWF-2000**: [Dataset](https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ‘¥ Contributors

- Model training & API development
- Based on CUE-Net architecture by Damith Senadeera et al.
